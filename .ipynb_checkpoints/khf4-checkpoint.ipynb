{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-08  15:27:43 INFO Downloading 600 train images for class 'wheel'\n",
      "100%|██████████| 600/600 [00:49<00:00, 12.05it/s]\n",
      "2020-11-08  15:28:33 INFO Downloading 600 train images for class 'dog'\n",
      " 97%|█████████▋| 583/600 [00:52<00:08,  1.98it/s]2020-11-08  15:29:32 WARNING Connection pool is full, discarding connection: open-images-dataset.s3.amazonaws.com\n",
      "100%|██████████| 600/600 [00:59<00:00, 10.12it/s]\n",
      "2020-11-08  15:29:32 INFO Downloading 600 train images for class 'monkey'\n",
      "100%|██████████| 600/600 [00:56<00:00, 10.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "#downloading 600 images from open images\n",
    "from openimages.download import download_images\n",
    "download_images(\"./khf4/images\", [\"Wheel\", \"Dog\", \"Monkey\"], limit= 600, exclusions_path = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "import glob\n",
    "from matplotlib import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for loading the images from the different folders\n",
    "def load_images(path):\n",
    "    image_list = []\n",
    "    for i, filename in enumerate(listdir(path)): \n",
    "        im=image.imread(path + filename)\n",
    "        image_list.append(im)\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the images into the memory\n",
    "wheels = np.asarray(load_images(\"./images/wheel/images/\"))\n",
    "dogs = np.asarray(load_images(\"./images/dog/images/\"))\n",
    "monkeys = np.asarray(load_images(\"./images/monkey/images/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3201"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#freeing up memory because my laptop could barely manage with this many things in memory\n",
    "import gc\n",
    "\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting the images into one list\n",
    "X = np.concatenate((wheels, dogs, monkeys), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the picture is greyscale (only 2 dimensions) convert it to rgb\n",
    "for i in range(len(X)):\n",
    "    if (len(X[i].shape) == 2):\n",
    "        X[i] = np.stack((X[i], X[i], X[i]), axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resizeing the images into shape (299, 299, 3), because the inception-V3 needs that input shape\n",
    "from skimage.transform import resize\n",
    "\n",
    "\n",
    "for i in range(len(X)):\n",
    "    X[i] = resize(X[i], (299, 299))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inception-V3 preprocess\n",
    "def preprocess_input(x):\n",
    "    x -= 0.5\n",
    "    x *= 2.\n",
    "\n",
    "\n",
    "preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the list into numpy arrays because the .fit raises errors otherwise\n",
    "def into_array(list):\n",
    "    r_array = np.empty((len(list), 299, 299, 3), dtype=np.float32)\n",
    "    for i in range(len(list)):\n",
    "        r_array[i] = list[i]\n",
    "    return r_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the input data into train, valid, test\n",
    "X_train = into_array(np.concatenate((X[:400], X[600:1000], X[1200:1600]), axis = 0))\n",
    "X_valid = into_array(np.concatenate((X[400:500], X[1000:1100], X[1600:1700]), axis = 0))\n",
    "X_test = into_array(np.concatenate((X[500:600], X[1100:1200], X[1700:1800]), axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the one-hot encoded output data\n",
    "Y_train = np.concatenate(([[1, 0, 0]]*400, [[0, 1, 0]]*400, [[0, 0, 1]]*400))\n",
    "Y_valid = np.concatenate(([[1, 0, 0]]*100, [[0, 1, 0]]*100, [[0, 0, 1]]*100))\n",
    "Y_test = np.concatenate(([[1, 0, 0]]*100, [[0, 1, 0]]*100, [[0, 0, 1]]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for the neural net\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3,preprocess_input,decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading the InceptionV3 model without the top\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "#the tensorboard logging\n",
    "tb = TensorBoard(log_dir='logs', histogram_freq=1, write_graph=1, update_freq='batch')\n",
    "\n",
    "#adding a global avaragepool layer and a dense layer to the model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "#adding the last layer with 3 outputs because the categorical crossentropy needs it that way\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "#and finally making the model with the input and output\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the base model not trainable\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#and compiling the model with Adam optimizer and the categorical crossentropy loss function\n",
    "model.compile(optimizer=Adam(0.0001), metrics=['accuracy'],loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "38/38 [==============================] - 72s 2s/step - loss: 0.4157 - accuracy: 0.8900 - val_loss: 0.2228 - val_accuracy: 0.9367\n",
      "Epoch 2/2\n",
      "38/38 [==============================] - 74s 2s/step - loss: 0.1218 - accuracy: 0.9733 - val_loss: 0.2025 - val_accuracy: 0.9367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa185ade040>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting the model\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=2, shuffle=True, \n",
    "          validation_data=(X_valid, Y_valid),  verbose=1, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers[:172]:\n",
    "       layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "       layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), metrics=['accuracy'], loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "75/75 [==============================] - 133s 2s/step - loss: 0.1959 - accuracy: 0.9417 - val_loss: 0.1938 - val_accuracy: 0.9433\n",
      "Epoch 2/2\n",
      "75/75 [==============================] - 135s 2s/step - loss: 0.1313 - accuracy: 0.9625 - val_loss: 0.1953 - val_accuracy: 0.9400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa184e74700>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size=16, epochs=2, shuffle=True, \n",
    "          validation_data=(X_valid, Y_valid),  verbose=1, callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-5ae2a4887d052399\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-5ae2a4887d052399\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the accuracy and the confusion matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "#function to test\n",
    "def test_error(model):\n",
    "    #predicting for the test values\n",
    "    preds=model.predict(X_test)\n",
    "    #getting the argmax of the prediction and the expected output\n",
    "    y_pred = np.argmax(preds, 1)\n",
    "    y_true = np.argmax(Y_test, 1)\n",
    "    #making the accuracy score and the confusion matrix\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    cmatrix = confusion_matrix(y_true, y_pred)\n",
    "    print(f\"the test accuracy is: {accuracy}\")\n",
    "    print(f\"the test confusion matrix is: \\n\\n{cmatrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test accuracy is: 0.97\n",
      "the test confusion matrix is: \n",
      "\n",
      "[[97  3  0]\n",
      " [ 1 97  2]\n",
      " [ 3  0 97]]\n"
     ]
    }
   ],
   "source": [
    "test_error(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
